# *pytorch*&*NLP*学习进度（2026）

## 1.14-2.12

期末考试结束后的这段时间，我进行了对*AI*知识的探索和广泛地学习。通过初步了解*AI*的各个理论和应用领域，找寻自己喜欢的方向。这将近一个月的时间里，我主要学习了吴恩达的*Machine Learning*课程，部分数学知识，基础的*pytorch*使用（比如建立线性回归模型，以*sigmoid*函数为基础的逻辑回归模型），以及基础的数据结构（例如树、图、队列、栈等等）。

不过这段时间我学习的内容多而杂，广而不精，一方面是因为在积极探索各方面的知识，另一方面是没能找到明确的方向。

## 2.13-2.15（除夕前）

在老师的指引下，我决定先把重心放在*pytorch*的学习上。我没有纠结于各个架构的底层数学原理，而是学习如何快速上手。结合AI的回答和李沐老师的课程，我利用*pytorch*实现了一个简单的*LSTM*模型，用于文本的情感分类。这让我很有成就感。

与此同时，我开始学习*NLP*相关的基础知识。跟随吴恩达老师的课程，我学会了朴素贝叶斯模型、*PNN*和*LSTM*、词嵌入等知识点。朴素贝叶斯最令我印象深刻，因为这个模型的核心公式——贝叶斯公式，是高中时的知识，但我没想到怎么早就能看到它在现代*AI*领域的应用，这让我有种莫名的兴奋。

## 2.16-2.18 

美好的春节，新年新气象！

## 2.19-2.20 

这两天我学习了感知机、多层感知机、针对不同激活函数的初始化方法（Xavier和He初始化），并且学习了如何利用pytorch实现它们。

## 2.21

今天我学习了基于nn.Module的模型构建，核心概念是“块”；学习了预测房价的实例，从中学习到了利用scikit-learn进行简单的数据预处理、利用RMSE计算相对误差。

## 2.22

今天，我学习了参数管理、自定义层、文件的读写、使用GPU等内容的基础pytorch操作。之前的模型构建和自定义层有很多相似之处。学习文件读写时，我总感觉简单的save和load难以满足复杂的工程需求，也许以后可以再学学sklearn和tensorflow。

之前学习的吴恩达NLP课程搁置了几天，主要原因便是卡在了许多算法的数学基础上，比如PCA就涉及到了矩阵SVD分解等等我还没学到的知识点。。。我从b站上找到了3blue的线代课程，听说能建立起对线代的几何直觉。如果能够达到这个目标，对我以后高等代数的学习也是件好事,所以明天开始我打算利用闲暇时间听听线代课。